{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg():\n",
    "    seed=1\n",
    "    no_cuda=True\n",
    "    batch_size=100\n",
    "    intermediate_size=128 #usual hidden size, linear around z\n",
    "    hidden_size=30 # latent space z\n",
    "    test_batch_size=100\n",
    "    epochs=5\n",
    "    lr=1e-3 #0.001\n",
    "    momentum=0.5\n",
    "    log_interval=10\n",
    "    save_model=True\n",
    "        \n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 32, 128)#FC 128\n",
    "        #F*((I−K+2P)/S+1)\n",
    "        \n",
    "        # Latent space\n",
    "        self.fc21 = nn.Linear(128, 20)\n",
    "        self.fc22 = nn.Linear(128, 20)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(20, 128)\n",
    "        self.fc4 = nn.Linear(128, 8192)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv5 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(out))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        out = self.relu(self.fc4(h3))\n",
    "        # import pdb; pdb.set_trace()\n",
    "        out = out.view(out.size(0), 32, 16, 16)\n",
    "        out = self.relu(self.deconv1(out))\n",
    "        out = self.relu(self.deconv2(out))\n",
    "        out = self.relu(self.deconv3(out))\n",
    "        out = self.sigmoid(self.conv5(out))\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x) \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def main3():\n",
    "    args=arg()\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if not args.no_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=True, download=True,\n",
    "                     transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('../data', train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    \n",
    "    #https://stackoverflow.com/questions/37512290/reading-cifar10-dataset-in-batches\n",
    "    data_iter = iter(train_loader)\n",
    "    \n",
    "    #how to save fixed inputs for debugging\n",
    "    fixed_x, _ = next(data_iter)\n",
    "    save_image(Variable(fixed_x).data.cpu(), './data/vae_real_images.png')\n",
    "    #args.fixed_x = to_var(fixed_x.view(fixed_x.size(0), -1)) #nur erstes batch i think als baeline\n",
    "    args.fixed_x = Variable(fixed_x, volatile=True)\n",
    "    #args.fixed_x = to_var(fixed_x)\n",
    "    model = VAE()\n",
    "    if not args.no_cuda:\n",
    "        model.cuda()\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "        \n",
    "    def loss_function(recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        #kullbach-leibler divergence\n",
    "        return BCE + KLD\n",
    "\n",
    "\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = Variable(data)\n",
    "            if not args.no_cuda:\n",
    "                data = data.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.data[0]\n",
    "            optimizer.step()\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.data[0] / len(data)))\n",
    "\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        # save the reconstructed images\n",
    "        reconst_images, mu, logvar  = model(args.fixed_x)\n",
    "        reconst_images = reconst_images.view(reconst_images.size(0), 3, 32, 32)\n",
    "        save_image(reconst_images.data.cpu(), './data/vae_reconst_images_%d.png' % (epoch))\n",
    "\n",
    "\n",
    "    def test(epoch):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            if not args.no_cuda:\n",
    "                data = data.cuda()\n",
    "            data = Variable(data, volatile=True)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).data[0]\n",
    "            '''            if epoch == args.epochs and i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                       recon_batch[:n]])\n",
    "                save_image(comparison.data.cpu(),\n",
    "                           'snapshots/conv_vae/reconstruction_' + str(epoch) +\n",
    "                           '.png', nrow=n)'''\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        '''if epoch == args.epochs:\n",
    "            sample = Variable(torch.randn(64, args.hidden_size))\n",
    "            if not args.no_cuda:\n",
    "                sample = sample.cuda()\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.data.view(64, 3, 32, 32),\n",
    "                       'snapshots/conv_vae/sample_' + str(epoch) + '.png')'''\n",
    "        torch.save(model.state_dict(), \"cifar_vae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main4():\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            '''old: self.conv1 = nn.Conv2d(1, 20, 5, 1)#in out kernel_sz stride\n",
    "            self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "            self.fc1 = nn.Linear(4 * 4 * 50, 500) # in out\n",
    "            self.fc2 = nn.Linear(500, 10)'''\n",
    "             # Encoder\n",
    "            self.conv1 = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n",
    "            self.conv2 = nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0)\n",
    "            self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.fc1 = nn.Linear(16 * 16 * 32, 128)#FC 128\n",
    "            #F*((I−K+2P)/S+1)\n",
    "            \n",
    "            '''# Latent space\n",
    "            self.fc21 = nn.Linear(128, 20)\n",
    "            self.fc22 = nn.Linear(128, 20)'''\n",
    "            # Decoder\n",
    "            '''self.fc3 = nn.Linear(20, 128)'''\n",
    "            self.fc4 = nn.Linear(128, 8192)\n",
    "            self.deconv1 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "            self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2, padding=0)\n",
    "            self.conv5 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "            \n",
    "            self.relu = nn.ReLU()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "        def encode(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            #x = F.max_pool2d(x, 2, 2)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            #x = F.max_pool2d(x, 2, 2)\n",
    "            x = F.relu(self.conv3(x))\n",
    "            #x = F.max_pool2d(x, 2, 2)\n",
    "            x = F.relu(self.conv4(x))\n",
    "            #x = F.max_pool2d(x, 2, 2)\n",
    "            \n",
    "            x = x.view(x.size(0),-1)\n",
    "            \n",
    "            return F.relu(self.fc1(x))\n",
    "        def normalize(self, x):\n",
    "            x_normed = x / x.max(0, keepdim=True)[0] \n",
    "            return x_normed\n",
    "            #alpha=(x-x.mean())\n",
    "            #beta=alpha/x.std()\n",
    "            #return beta\n",
    "            \n",
    "        def decode(self, x):\n",
    "            out = self.relu(self.fc4(x))\n",
    "            # import pdb; pdb.set_trace()\n",
    "            out = out.view(out.size(0), 32, 16, 16)\n",
    "            out = self.relu(self.deconv1(out))\n",
    "            out = self.relu(self.deconv2(out))\n",
    "            out = self.relu(self.deconv3(out))\n",
    "            out = self.sigmoid(self.conv5(out))\n",
    "            return out\n",
    "            \n",
    "        def forward(self, x):\n",
    "            mu = self.encode(x)\n",
    "            #return F.log_softmax(x, dim=1)\n",
    "            mu_0=self.normalize(mu)\n",
    "            return self.decode(mu_0),mu_0\n",
    "        \n",
    "    '''def loss_function(recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        #kullbach-leibler divergence\n",
    "        return BCE + KLD'''\n",
    "    \n",
    "    def loss_function(recon_x, x):\n",
    "        BCE = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "        return BCE \n",
    "    \n",
    "    def train(args, model, device, train_loader, optimizer, epoch):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)[0]\n",
    "            loss = loss_function(output, data)\n",
    "            loss.backward()\n",
    "            \n",
    "            #loss = F.nll_loss(output, target)\n",
    "            #loss.backward()\n",
    "            \n",
    "            train_loss += loss.data[0]\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "            '''if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.item()))'''\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.data[0] / len(data)))\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "        # save the reconstructed images\n",
    "        reconst_images = model(args.fixed_x)\n",
    "        \n",
    "        ##\n",
    "        #print(my_variable.data.cpu().numpy())\n",
    "        #x = Variable()\n",
    "        #print(np.shape(reconst_images.data.cpu().numpy()[0]))\n",
    "        reconst_images = reconst_images.view(reconst_images.size(0), 3, 32, 32)\n",
    "        save_image(reconst_images.data.cpu(), './data/linear_reconst_images_%d.png' % (epoch))\n",
    "\n",
    "    def test(args, model, device, test_loader):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)[0]\n",
    "                #nochma angucken\n",
    "                #test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss, negative log likelihood loss.\n",
    "                \n",
    "                test_loss += loss_function(output, data).data[0]\n",
    "                \n",
    "                pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item() #accuracy, elementwise equality, and sum\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    args=arg()\n",
    "        \n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('../data', train=True, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = Net().to(device)\n",
    "    \n",
    "    #model = Net()\n",
    "    #if not args.no_cuda:\n",
    "    #    model.cuda()\n",
    "        \n",
    "    #optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "    #gradients tend to vanish or explode\n",
    "    '''It uses a moving average of squared gradients to normalize the gradient itself. \n",
    "    That has an effect of balancing the step size — decrease the step for large gradient \n",
    "    to avoid exploding, and \n",
    "    increase the step for small gradient to avoid vanishing'''\n",
    "    \n",
    "    \n",
    "    #how to save fixed inputs for debugging\n",
    "    data_iter = iter(train_loader)\n",
    "    fixed_x, _ = next(data_iter)\n",
    "    save_image(Variable(fixed_x).data.cpu(), './data/CIFAR_real_images.png')\n",
    "    args.fixed_x = to_var(fixed_x) \n",
    "    #args.fixed_x = to_var(fixed_x.view(fixed_x.size(0), -1)) \n",
    "    #args.fixed_x=args.fixed_x.to(device)\n",
    "    #print(np.shape(args.fixed_x.data.cpu().numpy()))\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "        if (args.save_model):\n",
    "            torch.save(model.state_dict(), f\"cifar_cnn_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuong\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\Nuong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:99: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "C:\\Users\\Nuong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:111: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2178.300537\n",
      "Train Epoch: 1 [1000/50000 (2%)]\tLoss: 435.868835\n",
      "Train Epoch: 1 [2000/50000 (4%)]\tLoss: -3241.299072\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-bc1c170ef4c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-34c2a6af3419>\u001b[0m in \u001b[0;36mmain4\u001b[1;34m()\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-34c2a6af3419>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;31m#loss = F.nll_loss(output, target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
