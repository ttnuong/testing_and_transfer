{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pdb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trixi.logger.experiment.pytorchexperimentlogger import PytorchExperimentLogger\n",
    "from trixi.logger import PytorchVisdomLogger\n",
    "from trixi.util import Config\n",
    "\n",
    "Exp = PytorchExperimentLogger(base_dir=\"./experiment_dir\", \n",
    "                              experiment_name=\"test-experiment\",\n",
    "                              folder_format=\"{experiment_name}\")\n",
    "\n",
    "Viz = PytorchVisdomLogger(name=\"main\", port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg():\n",
    "    seed=1\n",
    "    no_cuda=True\n",
    "    batch_size=100\n",
    "    intermediate_size=128 #usual hidden size, linear around z\n",
    "    hidden_size=30 # latent space z\n",
    "    test_batch_size=100\n",
    "    epochs=3\n",
    "    lr=1e-1 #0.001\n",
    "    momentum=0.5\n",
    "    log_interval=10\n",
    "    save_model=True\n",
    "    experiment=2\n",
    "        \n",
    "    if not os.path.exists(f\"./exp{experiment}\"):\n",
    "         os.makedirs(f\"./exp{experiment}\")\n",
    "            \n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 32, 128)#FC 128\n",
    "        #F*((Iâˆ’K+2P)/S+1)\n",
    "        \n",
    "        # Latent space\n",
    "        self.fc21 = nn.Linear(128, 20)\n",
    "        self.fc22 = nn.Linear(128, 20)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(20, 128)\n",
    "        self.fc4 = nn.Linear(128, 8192)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv5 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(out))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        out = self.relu(self.fc4(h3))\n",
    "        # import pdb; pdb.set_trace()\n",
    "        out = out.view(out.size(0), 32, 16, 16)\n",
    "        out = self.relu(self.deconv1(out))\n",
    "        out = self.relu(self.deconv2(out))\n",
    "        out = self.relu(self.deconv3(out))\n",
    "        out = self.sigmoid(self.conv5(out))\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x) \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def main3():\n",
    "    args=arg()\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if not args.no_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True,\n",
    "                     transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    \n",
    "    #https://stackoverflow.com/questions/37512290/reading-cifar10-dataset-in-batches\n",
    "    data_iter = iter(train_loader)\n",
    "    \n",
    "    #how to save fixed inputs for debugging\n",
    "    fixed_x, _ = next(data_iter)\n",
    "    save_image(Variable(fixed_x).data.cpu(), './data/vae_real_images.png')\n",
    "    #args.fixed_x = to_var(fixed_x.view(fixed_x.size(0), -1)) #nur erstes batch i think als baeline\n",
    "    args.fixed_x = Variable(fixed_x, volatile=True)\n",
    "    #args.fixed_x = to_var(fixed_x)\n",
    "    model = VAE()\n",
    "    if not args.no_cuda:\n",
    "        model.cuda()\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "        \n",
    "    def loss_function(recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        #kullbach-leibler divergence\n",
    "        return BCE + KLD\n",
    "\n",
    "\n",
    "    def train(epoch):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = Variable(data)\n",
    "            if not args.no_cuda:\n",
    "                data = data.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.item() / len(data)))\n",
    "\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "              epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        # save the reconstructed images\n",
    "        reconst_images, mu, logvar  = model(args.fixed_x)\n",
    "        reconst_images = reconst_images.view(reconst_images.size(0), 3, 32, 32)\n",
    "        save_image(reconst_images.data.cpu(), './data/vae_reconst_images_%d.png' % (epoch))\n",
    "\n",
    "\n",
    "    def test(epoch):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            if not args.no_cuda:\n",
    "                data = data.cuda()\n",
    "            data = Variable(data, volatile=True)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            '''            if epoch == args.epochs and i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                       recon_batch[:n]])\n",
    "                save_image(comparison.data.cpu(),\n",
    "                           'snapshots/conv_vae/reconstruction_' + str(epoch) +\n",
    "                           '.png', nrow=n)'''\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        '''if epoch == args.epochs:\n",
    "            sample = Variable(torch.randn(64, args.hidden_size))\n",
    "            if not args.no_cuda:\n",
    "                sample = sample.cuda()\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.data.view(64, 3, 32, 32),\n",
    "                       'snapshots/conv_vae/sample_' + str(epoch) + '.png')'''\n",
    "        torch.save(model.state_dict(), \"vae_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main4(load_old=False):\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            '''old: self.conv1 = nn.Conv2d(1, 20, 5, 1)#in out kernel_sz stride\n",
    "            self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "            self.fc1 = nn.Linear(4 * 4 * 50, 500) # in out\n",
    "            self.fc2 = nn.Linear(500, 10)'''\n",
    "             # Encoder\n",
    "            #32x32x3\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)#32x32x32\n",
    "            self.conv2 = nn.Conv2d(32, 96, kernel_size=2, stride=2, padding=0)#16x16x96\n",
    "            self.conv3 = nn.Conv2d(96, 256, kernel_size=3, stride=1, padding=1)#16x16x256\n",
    "            self.conv3b = nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0)#8x8x512\n",
    "            self.conv4 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)#8x8x1024\n",
    "            self.fc1a = nn.Linear(8 * 8 * 1024, 16384)\n",
    "            self.fc1b = nn.Linear(16384, 2048)\n",
    "            self.fc1c = nn.Linear(2048, 180)\n",
    "            #FC 32x32/240x240= 0,177\n",
    "            #F*((Iâˆ’K+2P)/S+1)\n",
    "            #m1: [100 x 16384], m2: [16364 x 2048]\n",
    "            '''# Latent space\n",
    "            self.fc21 = nn.Linear(128, 20)\n",
    "            self.fc22 = nn.Linear(128, 20)'''\n",
    "            # Decoder\n",
    "            '''self.fc3 = nn.Linear(20, 128)'''\n",
    "            self.fc4a = nn.Linear(180, 2048)\n",
    "            self.fc4b = nn.Linear(2048, 16384)\n",
    "            self.fc4c = nn.Linear(16384, 65536)\n",
    "            self.deconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=3, stride=1, padding=1)\n",
    "            self.deconv1b = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2, padding=0)\n",
    "            self.deconv2 = nn.ConvTranspose2d(256, 96, kernel_size=3, stride=1, padding=1)\n",
    "            self.deconv3 = nn.ConvTranspose2d(96, 32, kernel_size=2, stride=2, padding=0)\n",
    "            self.conv5 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "            \n",
    "            self.relu = nn.ReLU()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "        def encode(self, x):\n",
    "            print(\"convolute\")\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.relu(self.conv3(x))\n",
    "            x = F.relu(self.conv3b(x))\n",
    "            x = F.relu(self.conv4(x))\n",
    "       \n",
    "            x = x.view(x.size(0),-1)\n",
    "            print(\"FC linear\")\n",
    "            #pdb.set_trace()\n",
    "            x = F.relu(self.fc1a(x))\n",
    "            x = F.relu(self.fc1b(x))\n",
    "            x = F.relu(self.fc1c(x))\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        def normalize(self, x):\n",
    "            #x_normed = x / x.max(0, keepdim=True)[0] \n",
    "            #return x_normed\n",
    "            alpha=(x-x.mean(0,keepdim=True))\n",
    "            beta=alpha/x.std(0,keepdim=True)\n",
    "            return beta\n",
    "            \n",
    "        def decode(self, x):\n",
    "            print(\"FC De-linear\")\n",
    "            out = self.relu(self.fc4a(x))\n",
    "            out = self.relu(self.fc4b(out))\n",
    "            out = self.relu(self.fc4c(out))\n",
    "            # import pdb; pdb.set_trace()\n",
    "            out = out.view(out.size(0), 1024, 8, 8)\n",
    "            print(\"De-convolute\")\n",
    "            out = self.relu(self.deconv1(out))\n",
    "            out = self.relu(self.deconv1b(out))\n",
    "            out = self.relu(self.deconv2(out))\n",
    "            out = self.relu(self.deconv3(out))\n",
    "            out = self.sigmoid(self.conv5(out))\n",
    "            return out\n",
    "            \n",
    "        def forward(self, x):\n",
    "            print(\"encode\")\n",
    "            mu = self.encode(x)\n",
    "            #return F.log_softmax(x, dim=1)\n",
    "            mu_0=self.normalize(mu)\n",
    "            #return self.decode(mu_0),mu_0\n",
    "            print(\"decode\")\n",
    "            return self.decode(mu),mu\n",
    "        \n",
    "    '''def loss_function(recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "\n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # https://arxiv.org/abs/1312.6114\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        #kullbach-leibler divergence\n",
    "        return BCE + KLD'''\n",
    "    \n",
    "    def loss_function(recon_x, x):\n",
    "        #pdb.set_trace()\n",
    "        BCE = F.binary_cross_entropy(recon_x.view(-1, 32 * 32 * 3),\n",
    "                                 x.view(-1, 32 * 32 * 3), size_average=False)\n",
    "        return BCE \n",
    "    \n",
    "    def train(args, model, device, train_loader, optimizer, epoch):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)[0]\n",
    "            loss = loss_function(output, data)\n",
    "            loss.backward()\n",
    "            \n",
    "            #loss = F.nll_loss(output, target)\n",
    "            #loss.backward()\n",
    "            \n",
    "            #train_loss += loss.data[0]\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            optimizer.step()\n",
    "            '''if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.item()))'''\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader),\n",
    "                    loss.item() / len(data)))\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "        # save the reconstructed images\n",
    "        reconst_images = model(args.fixed_x)[0]\n",
    "        \n",
    "        ##\n",
    "        #print(my_variable.data.cpu().numpy())\n",
    "        #x = Variable()\n",
    "        #print(np.shape(reconst_images.data.cpu().numpy()[0]))\n",
    "        reconst_images = reconst_images.view(reconst_images.size(0), 3, 32, 32)\n",
    "        save_image(reconst_images.data.cpu(), f'./data/exp{args.experiment}/CIFAR_reconst_images_%d.png' % (epoch))\n",
    "\n",
    "    def test(args, model, device, test_loader):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        #correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)[0]\n",
    "                #nochma angucken\n",
    "                #test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss, negative log likelihood loss.\n",
    "                \n",
    "                test_loss += loss_function(output, data).item()\n",
    "                #pdb.set_trace()\n",
    "                pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "                #correct += pred.eq(target.view_as(pred)).sum().item() #accuracy, elementwise equality, and sum\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        print('\\nTest set: Average loss: {:.4f}\\n'.format(\n",
    "            test_loss))\n",
    "    \n",
    "    args=arg()\n",
    "        \n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True,\n",
    "                      transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    \n",
    "    \n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    if load_old:\n",
    "        model=Net().to(device)\n",
    "        model.load_state_dict(torch.load(f\"exp{args.experiment}/cifar_cnn_5.pt\"))\n",
    "    else:\n",
    "        model = Net().to(device)\n",
    "    \n",
    "    #model = Net()\n",
    "    #if not args.no_cuda:\n",
    "    #    model.cuda()\n",
    "        \n",
    "    #optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "    #gradients tend to vanish or explode\n",
    "    '''It uses a moving average of squared gradients to normalize the gradient itself. \n",
    "    That has an effect of balancing the step sizeâ€Šâ€”â€Šdecrease the step for large gradient \n",
    "    to avoid exploding, and \n",
    "    increase the step for small gradient to avoid vanishing'''\n",
    "    \n",
    "    \n",
    "    #how to save fixed inputs for debugging\n",
    "    data_iter = iter(train_loader)\n",
    "    fixed_x, _ = next(data_iter)\n",
    "    #pdb.set_trace()\n",
    "    save_image(Variable(fixed_x).data.cpu(), './data/CIFAR_real_images.png')\n",
    "    args.fixed_x = to_var(fixed_x) \n",
    "    #args.fixed_x = to_var(fixed_x.view(fixed_x.size(0), -1)) \n",
    "    #args.fixed_x=args.fixed_x.to(device)\n",
    "    #print(np.shape(args.fixed_x.data.cpu().numpy()))\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(f\"in epoch {epoch}\")\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "        if (args.save_model):\n",
    "            torch.save(model.state_dict(), f\"exp{args.experiment}/cifar_cnn_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "in epoch 1\n",
      "encode\n",
      "convolute\n",
      "FC linear\n",
      "decode\n",
      "FC De-linear\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [100 x 16384], m2: [16364 x 65536] at c:\\a\\w\\1\\s\\tmp_conda_3.7_070403\\conda\\conda-bld\\pytorch-cpu_1550387224787\\work\\aten\\src\\th\\generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c8bb3187f874>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_old\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-35be8a6119fa>\u001b[0m in \u001b[0;36mmain4\u001b[1;34m(load_old)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"in epoch {epoch}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-35be8a6119fa>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thisenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-35be8a6119fa>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;31m#return self.decode(mu_0),mu_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"decode\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     '''def loss_function(recon_x, x, mu, logvar):\n",
      "\u001b[1;32m<ipython-input-3-35be8a6119fa>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;31m# import pdb; pdb.set_trace()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thisenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thisenv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\thisenv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [100 x 16384], m2: [16364 x 65536] at c:\\a\\w\\1\\s\\tmp_conda_3.7_070403\\conda\\conda-bld\\pytorch-cpu_1550387224787\\work\\aten\\src\\th\\generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "\n",
    "main4(load_old=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
